---
title: 机器学习——数据集划分法
date: 2019-01-11 17:16:57
tags: '机器学习(ML)'
categories: '技术文'
---

# 机器学习——数据集划分法
[TOC]
___________
<!-- more -->
>——周志华老师机器学习西瓜书的一些总结与备忘。

## 2.2训练与测试集的划分
### 2.2.1留出法 (hold-out)
![Alt text](D:\study\lyc.io\source\_posts\机器学习——数据集划分法\2.png)
+ 常见做法是将大约 $2/3、 4/5$ 的样本用于训练，剩余样本用于测试。
+ 需要注意测试与训练的样本分布要尽量相同。
### 2.2.2 交叉验证法 (K-fold cross validation)
![Alt text](D:\study\lyc.io\source\_posts\机器学习——数据集划分法\3.png)

+ 为减小 因样本划分不同而引入的差别 ， k 折交叉验证通常要随机使用不同的划分重复 p 次。最终的评估结果是这 p 次 k 折交叉验证结果的均值，例如常见的有10 次 10 折交叉验证。（实践中这么多折相当耗费计算能力，感觉不太会进行重复的k折取平均）
### 2.2.3留一法 (Leave-One-Out , LOO)
+ 假定数据集 D 中包含 m 个样本 , 若令 k=m ， 则得到了交叉验证法的 一个特例。 
+ 留一法不受样本随机划分方式的影响。（每折只包含一个测试样本，与直接用D进行训练的结果相似）
+ 感觉实际用途不大。。。先不说训练的时候往往是根据划分的交叉验证集上的测试结果来评定本次训练的优劣。因此验证集直接决定了每一折保存的是训练过程中的哪个模型。只留下一个样本作为交叉验证没有意义，除非有另外的测试集。如果是这种情况，还不如直接把所有数据都作为训练集。如果是为了使用K-fold融合多个模型提升效果，使用留一的方法过于极端，样本数量大时模型数量过多，样本较少时可以考虑。
### 2.2.4 自助法 (bootstrapping)
+ 但在留出法和交叉验证法中，由于保留了一部分样本用于测试，因此实际评估的模型所使用的训练集小，这必然会引入一些因训练样本规模不同而导致的估计偏差。

  ![](D:\study\lyc.io\source\_posts\机器学习——数据集划分法\1.png)

+ 自助法在数据集较小、难以有效划分训练/测试集时很有用

+ 此外，自助法能从初始数据集中产生多个不同的训练集，这对集成学习等方法有很大的好处.

+ 然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差.


>参考《周志华机器学习西瓜书》第二章